<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <title>Paper Summary - Rapid Learning or Feature Reuse? - Vaasudev's Blog</title>
    <meta charset="utf-8" />
    <link href="https://fonts.googleapis.com/css2?family=Comic+Neue&display=swap" rel="stylesheet" type="text/css" />
    <link rel="stylesheet" type="text/css" href="./theme/bootstrap.css" />
    <link rel="stylesheet" type="text/css" href="./theme/pastie.css" />
    <link href="https://vdevmcitylp.github.io/" type="application/atom+xml" rel="alternate" title="Vaasudev's Blog Atom Feed" />


    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
      extensions: ["tex2jax.js"],
        jax: ["input/TeX", "output/HTML-CSS"],
        tex2jax: {
          inlineMath: [[ '$','$']],
          displayMath:  [['$$','$$']],
          processEscapes: true
        },
        "HTML-CSS": { availableFonts: ["TeX"] }
      });
    </script> 

    <script type="text/javascript"          
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
      TeX: { equationNumbers: { autoNumber: "AMS" } }
      });
    </script>

  </head>

  <body>
    <div class="container">
      <div class="row">
        <div class="span8">
<div id="content">
    <div class="header">
        <h1>Paper Summary - Rapid Learning or Feature Reuse?</h1>
    </div>
    <p class="meta"><small><span><a href="./author/vaasudev-narayanan/">Vaasudev Narayanan</a> - </span><span>Mon 23 December 2019</span> - <span class="tags"><a href="/tag/meta-learning.html">meta-learning</a>, <a href="/tag/paper-summary.html">paper-summary</a></span></small></p>
        <div class="entry-content">
        <p>In this post, we will go through a brief summary of <a href="http://metalearning.ml/2019/papers/metalearn2019-raghu.pdf">this</a> paper by Aniruddh Raghu, Maithra Raghu. Samy Bengio &amp; Oriol Vinyals which came out in <a href="http://metalearning.ml/2019/">MetaLearn 2019</a> at NeurIPS.</p>
<p>The authors set out to understand the effectiveness of MAML by looking at the quality of the learnt meta-initialization.</p>
<ul>
<li><strong>Rapid Learning</strong>: Is the learnt meta-initialization such that it is amenable to large, efficient changes given a new task at meta-test time?</li>
</ul>
<p align = 'center'> OR </p>

<ul>
<li><strong>Feature Reuse</strong>: Is the learnt meta-initialization already at a point in the feature space which is close to the optimum for a new task at meta-test time?</li>
</ul>
<p><img alt="rapidvsreuse" src="./images/rapidvsreuse.png"></p>
<p><strong>Conclusion</strong></p>
<p>They conclude that feature reuse is the dominant factor and propose two modifications to MAML - Almost No Inner Loop (ANIL) &amp; No Inner Loop (NIL).</p>
<p><strong>Experiments</strong></p>
<p>The final classifier layer of the network is referred to as the <em>head</em> and the rest of the layers are referred to as the <em>body</em>.</p>
<ul>
<li>The body is the same as the one used in the MAML paper, four blocks of 3x3 convolutions &amp; 2x2 max-pooling.</li>
<li>Contiguous subsets of the layers in the body of the network are frozen during the inner loop at <em>meta-test</em> time.</li>
<li>The inner loop adaptation is still performed at <em>meta-train</em> time.</li>
</ul>
<p><img alt="rapidvreuse1" src="./images/rapidvsreuse1.png"></p>
<p><strong>Observation 1</strong>:</p>
<ul>
<li>The validation accuracy with inner loop adaptation (no freezing) and without the inner loop adaptation (freezing) is compared at meta-test time. </li>
<li>Almost identical performance is observed on MiniImageNet-5way-5shot.</li>
</ul>
<p><img alt="rapidvreuse2" src="./images/rapidvsreuse2.png"></p>
<p><strong>Observation 2</strong>:</p>
<ul>
<li><a href="https://ai.googleblog.com/2017/11/interpreting-deep-neural-networks-with.html">Canonical Correlational Analysis (CCA)</a>[1] similarity is used to compare the changes in representations of all layers.</li>
<li>Apart from the head, the rest of the layers have a high CCA similarity score, implying that the body is not affected by the inner adaptation.</li>
</ul>
<p><br></p>
<p><strong>Almost No Inner Loop (ANIL)</strong></p>
<p><img alt="rapidvreuse3" src="./images/rapidvsreuse3.png"></p>
<ul>
<li>Based on the above observations, the authors remove the inner loop adaptation during <strong>both</strong> meta-train &amp; meta-test time for the body of the network and propose ANIL.</li>
<li>Inner loop adaptations for the head of the network for task-specific alignment. This is required as for each task, the final output neurons correspond to a different set of classes.</li>
<li>ANIL matches the performance of MAML on both few shot classification and Reinforcement Learning tasks.</li>
</ul>
<p><br></p>
<p><strong>No Inner Loop (NIL)</strong></p>
<ul>
<li>In order to do away with the inner loop adaptation for the head during <em>meta-test</em> time, the authors propose NIL.</li>
<li>A meta-model is first learnt using ANIL.</li>
<li>At meta-test time, the head is removed. The features for the support set are computed by passing it through the body of the network.</li>
<li>For a data-point from the query set, cosine similarity is computed for each all data-points in the support set.</li>
<li>The similarity scores are then used to weight the labels of the support set to get the prediction. </li>
<li>This is done in the <a href="https://arxiv.org/abs/1606.04080">Matching Networks</a> paper [2].</li>
</ul>
<p><br>
<strong>My Thoughts</strong>:</p>
<ul>
<li>
<p>Does the dominance of the feature reuse paradigm imply that MAML might not work well for tasks which vary a lot from the training distriution? As mentioned in the conclusion, it will be interesting to conduct the same experiments on a more diverse set of datasets [3].</p>
</li>
<li>
<p>I felt that no experiments were conducted to test the rapid learning hypothesis. I'm not sure if feature reuse alone implies that rapid learning cannot happen. It'll be interesting to design experiments to test the rapid learning hypothesis.</p>
</li>
</ul>
<p>Considering the loss surface as a mountainous landscape, I would imagine the meta-initialization as a boulder lying on a hill from which we can push it along different steep pathways corresponding to different tasks. But as it turns out, the hill is not very high :P</p>
<p><br>
<strong>References</strong>:</p>
<p><a href="https://papers.nips.cc/paper/7188-svcca-singular-vector-canonical-correlation-analysis-for-deep-learning-dynamics-and-interpretability">[1]</a> Maithra Raghu, Justin Gilmer, Jason Yosinski, and Jascha Sohl-Dickstein. Svcca: Singular vector canonical correlation analysis for deep learning dynamics and interpretability. In Advances in Neural Information Processing Systems, pages 6076–6085, 2017</p>
<p><a href="https://arxiv.org/abs/1606.04080">[2]</a> Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et al. Matching networks for one shot learning. In Advances in neural information processing systems, pages 3630–3638, 2016</p>
<p><a href="https://arxiv.org/abs/1903.03096">[3]</a> Eleni Triantafillou, Tyler Zhu, Vincent Dumoulin, Pascal Lamblin, Kelvin Xu, Ross Goroshin, Carles Gelada, Kevin Swersky, Pierre-Antoine Manzagol, and Hugo Larochelle. Meta-dataset: A dataset of datasets for learning to learn from few examples. arXiv preprint arXiv:1903.03096, 2019.</p>
        </div><!-- /.entry-content -->
        <div id="disqus_thread"></div>
        <script type="text/javascript">
            /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
            var disqus_shortname = 'vdevmcitylp'; // required: replace example with your forum shortname

            /* * * DON'T EDIT BELOW THIS LINE * * */
            (function() {
                var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
        </div>
        <div class="span3 offset1">
          <div class="well">
            <ul class="nav nav-list">
              <li class="nav-header">Blog</li>
              <li ><a href="./index.html">Home</a></li>
              <li ><a href="./tags.html">Tags</a></li>
              <!-- <li ><a href="./archives/">Archiv</a></li> -->
              <li class="nav-header">Pages</li>
              <li><a href="./pages/about.html">About Me</a></li>
              <li><a href="./pages/publications.html">Publications</a></li>
              <li><a href="./pages/work-experience.html">Work Experience</a></li>
              <li class="nav-header">Links</li>
              <li><a href="https://drive.google.com/file/d/1pr3kPSXaziOdq45O0bSiSXuQ11Ez1bNf/view?usp=sharing">CV</a></li>
              <li><a href="https://scholar.google.co.in/citations?user=ncXa5P0AAAAJ&hl=en">Google Scholar</a></li>
              <li><a href="https://github.com/vdevmcitylp">Github</a></li>
              <li><a href="https://www.linkedin.com/in/vaasudev-narayanan-659b6010b/">LinkedIn</a></li>
              <li><a href="https://twitter.com/VDev_AGI">Twitter</a></li>
            </ul>
          </div><!-- /#menu -->
        </div>
      </div>

      <hr />

      <div class="row">
        <div class="span12">
          <div id="about">
            <p>Proudly powered by <a href="http://twitter.github.com/bootstrap/">bootstrap</a>, <a href="http://docs.notmyidea.org/alexis/pelican/">pelican</a>, <a href="http://python.org">python</a> and <a href="http://www.julo.ch/about/">Alex</a>!</p>
          </div>
        </div>
      </div>
    </div> 

    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'vdevmcitylp'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function () {
            var s = document.createElement('script'); s.async = true;
            s.type = 'text/javascript';
            s.src = 'https://' + disqus_shortname + '.disqus.com/count.js';
            (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
        }());
    </script>

  </body>
</html>