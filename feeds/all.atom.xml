<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Vaasudev's Blog</title><link href="https://vdevmcitylp.github.io/" rel="alternate"></link><link href="https://vdevmcitylp.github.io/feeds/all.atom.xml" rel="self"></link><id>https://vdevmcitylp.github.io/</id><updated>2019-12-23T11:44:00+05:30</updated><entry><title>Paper Summary - Rapid Learning or Feature Reuse?</title><link href="https://vdevmcitylp.github.io/paper-summary-rapid-learning-or-feature-reuse.html" rel="alternate"></link><published>2019-12-23T11:44:00+05:30</published><updated>2019-12-23T11:44:00+05:30</updated><author><name>Vaasudev Narayanan</name></author><id>tag:vdevmcitylp.github.io,2019-12-23:/paper-summary-rapid-learning-or-feature-reuse.html</id><summary type="html">&lt;p&gt;Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness of MAML (NeurIPS Workshop on Meta Learning 2019)&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this post, we will go through a brief summary of &lt;a href="http://metalearning.ml/2019/papers/metalearn2019-raghu.pdf"&gt;this&lt;/a&gt; paper by Aniruddh Raghu, Maithra Raghu. Samy Bengio &amp;amp; Oriol Vinyals which came out in &lt;a href="http://metalearning.ml/2019/"&gt;MetaLearn 2019&lt;/a&gt; at NeurIPS.&lt;/p&gt;
&lt;p&gt;The authors set out to understand the effectiveness of MAML by looking at the quality of the learnt meta-initialization.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Rapid Learning&lt;/strong&gt;: Is the learnt meta-initialization such that it is amenable to large, efficient changes given a new task at meta-test time?&lt;/li&gt;
&lt;/ul&gt;
&lt;p align = 'center'&gt; OR &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Feature Reuse&lt;/strong&gt;: Is the learnt meta-initialization already at a point in the feature space which is close to the optimum for a new task at meta-test time?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="rapidvsreuse" src="https://vdevmcitylp.github.io/images/rapidvsreuse.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;They conclude that feature reuse is the dominant factor and propose two modifications to MAML - Almost No Inner Loop (ANIL) &amp;amp; No Inner Loop (NIL).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Experiments&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The final classifier layer of the network is referred to as the &lt;em&gt;head&lt;/em&gt; and the rest of the layers are referred to as the &lt;em&gt;body&lt;/em&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The body is the same as the one used in the MAML paper, four blocks of 3x3 convolutions &amp;amp; 2x2 max-pooling.&lt;/li&gt;
&lt;li&gt;Contiguous subsets of the layers in the body of the network are frozen during the inner loop at &lt;em&gt;meta-test&lt;/em&gt; time.&lt;/li&gt;
&lt;li&gt;The inner loop adaptation is still performed at &lt;em&gt;meta-train&lt;/em&gt; time.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="rapidvreuse1" src="https://vdevmcitylp.github.io/images/rapidvsreuse1.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Observation 1&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The validation accuracy with inner loop adaptation (no freezing) and without the inner loop adaptation (freezing) is compared at meta-test time. &lt;/li&gt;
&lt;li&gt;Almost identical performance is observed on MiniImageNet-5way-5shot.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="rapidvreuse2" src="https://vdevmcitylp.github.io/images/rapidvsreuse2.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Observation 2&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://ai.googleblog.com/2017/11/interpreting-deep-neural-networks-with.html"&gt;Canonical Correlational Analysis (CCA)&lt;/a&gt;[1] similarity is used to compare the changes in representations of all layers.&lt;/li&gt;
&lt;li&gt;Apart from the head, the rest of the layers have a high CCA similarity score, implying that the body is not affected by the inner adaptation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Almost No Inner Loop (ANIL)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="rapidvreuse3" src="https://vdevmcitylp.github.io/images/rapidvsreuse3.png"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Based on the above observations, the authors remove the inner loop adaptation during &lt;strong&gt;both&lt;/strong&gt; meta-train &amp;amp; meta-test time for the body of the network and propose ANIL.&lt;/li&gt;
&lt;li&gt;Inner loop adaptations for the head of the network for task-specific alignment. This is required as for each task, the final output neurons correspond to a different set of classes.&lt;/li&gt;
&lt;li&gt;ANIL matches the performance of MAML on both few shot classification and Reinforcement Learning tasks.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;No Inner Loop (NIL)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In order to do away with the inner loop adaptation for the head during &lt;em&gt;meta-test&lt;/em&gt; time, the authors propose NIL.&lt;/li&gt;
&lt;li&gt;A meta-model is first learnt using ANIL.&lt;/li&gt;
&lt;li&gt;At meta-test time, the head is removed. The features for the support set are computed by passing it through the body of the network.&lt;/li&gt;
&lt;li&gt;For a data-point from the query set, cosine similarity is computed for each all data-points in the support set.&lt;/li&gt;
&lt;li&gt;The similarity scores are then used to weight the labels of the support set to get the prediction. &lt;/li&gt;
&lt;li&gt;This is done in the &lt;a href="https://arxiv.org/abs/1606.04080"&gt;Matching Networks&lt;/a&gt; paper [2].&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;
&lt;strong&gt;My Thoughts&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Does the dominance of the feature reuse paradigm imply that MAML might not work well for tasks which vary a lot from the training distriution? As mentioned in the conclusion, it will be interesting to conduct the same experiments on a more diverse set of datasets [3].&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I felt that no experiments were conducted to test the rapid learning hypothesis. I'm not sure if feature reuse alone implies that rapid learning cannot happen. It'll be interesting to design experiments to test the rapid learning hypothesis.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Considering the loss surface as a mountainous landscape, I would imagine the meta-initialization as a boulder lying on a hill from which we can push it along different steep pathways corresponding to different tasks. But as it turns out, the hill is not very high :P&lt;/p&gt;
&lt;p&gt;&lt;br&gt;
&lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://papers.nips.cc/paper/7188-svcca-singular-vector-canonical-correlation-analysis-for-deep-learning-dynamics-and-interpretability"&gt;[1]&lt;/a&gt; Maithra Raghu, Justin Gilmer, Jason Yosinski, and Jascha Sohl-Dickstein. Svcca: Singular vector canonical correlation analysis for deep learning dynamics and interpretability. In Advances in Neural Information Processing Systems, pages 6076–6085, 2017&lt;/p&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1606.04080"&gt;[2]&lt;/a&gt; Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et al. Matching networks for one shot learning. In Advances in neural information processing systems, pages 3630–3638, 2016&lt;/p&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1903.03096"&gt;[3]&lt;/a&gt; Eleni Triantafillou, Tyler Zhu, Vincent Dumoulin, Pascal Lamblin, Kelvin Xu, Ross Goroshin, Carles Gelada, Kevin Swersky, Pierre-Antoine Manzagol, and Hugo Larochelle. Meta-dataset: A dataset of datasets for learning to learn from few examples. arXiv preprint arXiv:1903.03096, 2019.&lt;/p&gt;</content><category term="posts"></category></entry><entry><title>Deriving the MAML Objective - 2</title><link href="https://vdevmcitylp.github.io/deriving-the-maml-objective-2.html" rel="alternate"></link><published>2019-11-14T14:10:00+05:30</published><updated>2019-11-14T14:10:00+05:30</updated><author><name>Vaasudev Narayanan</name></author><id>tag:vdevmcitylp.github.io,2019-11-14:/deriving-the-maml-objective-2.html</id><summary type="html">&lt;p&gt;Mean Squared Error&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this post, we'll be deriving the meta-gradient of the &lt;a href="https://arxiv.org/pdf/1703.03400.pdf"&gt;MAML&lt;/a&gt; objective for the &lt;em&gt;Mean Squared Error (MSE)&lt;/em&gt; loss. &lt;br /&gt;
This is a follow-up to &lt;a href="https://vdevmcitylp.github.io/deriving-the-maml-objective-1.html"&gt;Deriving the MAML Objective - 1.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In our setup, we have $n$ tasks and the meta-update is defined as,&lt;/p&gt;
&lt;p&gt;$$
\begin{equation} \label{eq1}
    \theta := \theta - \beta \nabla_\theta\sum_{T_{i = 1}}^n L_{T_i}(f_{\theta_i'})
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;We are interested in calculating $ \nabla_\theta\sum_{T_{i = 1}}^n L_{T_i}(f_{\theta_i'}) $ where $L$ is the mean-squared error defined as,
$ \newcommand{\norm}[1]{\left\lVert #1 \right\rVert} $
$$
\begin{equation} \label{eq2}
    L_{T_i}(f_{\theta_i'}) = \frac{1}{2} \sum_{j = 1}^K \norm{f_{\theta_i'}(x^{(j)}) - y^{(j)}}_{2}^{2}
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;We will consider the simpler case of a single-output regression task. So, &lt;/p&gt;
&lt;p&gt;$$
\begin{equation} \label{eq3}
    L_{T_i}(f_{\theta_i'}) = \frac{1}{2} \sum_{j = 1}^K (f_{\theta_i'}(x^{(j)}) - y^{(j)})^{2}
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;The gradient for the $ i^{th} $ task is defined as,&lt;/p&gt;
&lt;p&gt;$$
\begin{equation} \label{eq4}
    \frac{\partial L_{T_i}(f_{\theta_i'})}{\partial \theta} = \frac{\partial L_{T_i}(f_{\theta_i'})}{\partial \theta_i'} \cdot
    \frac{\partial \theta_i'}{\partial \theta}
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;The first term of equation \ref{eq4}, $ \frac{\partial L_{T_i}(f_{\theta_i'})}{\partial \theta_i'} $ is the derivative of the task loss function w.r.t. to the task-adapted parameters,&lt;/p&gt;
&lt;p&gt;$$ 
\begin{equation}
    \begin{split}
        \frac{\partial L_{T_i}(f_{\theta_i'})}{\partial \theta_i'} &amp;amp;= \frac{\partial L_{T_i}(f_{\theta_i'})}{\partial f_{\theta_i'}} \cdot \frac{\partial f_{\theta_i'}}{\partial \theta_i'} \\
        &amp;amp;= \sum_{k = 1}^K (f_{\theta_i'}(x^{(k)}) - y^{(k)}) \cdot \frac{\partial f_{\theta_i'}}{\partial \theta_i'} (x^{(k)})
    \end{split}
    \label{eq5}
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;K is the number of data-points for a task in a K-shot setting.
&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;The second term of equation \ref{eq3}, $ \frac{\partial \theta_i'}{\partial \theta} $ is the derivative of the task-adapted parameters w.r.t. the meta-parameters.&lt;/p&gt;
&lt;p&gt;To calculate $ \frac{\partial \theta_i'}{\partial \theta} $, let us assume that $ \theta_i' $ and $ \theta $ are both (D+1)-dimensional vectors,&lt;/p&gt;
&lt;p&gt;$$
\begin{equation}
    \begin{split}
        &amp;amp;\theta_i' = [\theta_{i0}', \theta_{i1}', \dots, \theta_{iD}'] \\
        &amp;amp;\theta = [\theta_0, \theta_1, \dots, \theta_D]
    \end{split}
    \label{eq6}
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;Then the Jacobian is defined as,&lt;/p&gt;
&lt;p&gt;$$
\begin{equation} \label{eq7}
    \frac{\partial \theta_i'}{\partial \theta} = 
    \begin{bmatrix}
        \frac{\partial \theta_{i0}'}{\partial \theta_0} &amp;amp; \frac{\partial \theta_{i0}'}{\partial \theta_1} &amp;amp; \dots &amp;amp; \frac{\partial \theta_{i0}'}{\partial \theta_D} \\
        \frac{\partial \theta_{i1}'}{\partial \theta_0} &amp;amp; \frac{\partial \theta_{i1}'}{\partial \theta_1} &amp;amp; \dots &amp;amp; \frac{\partial \theta_{i1}'}{\partial \theta_D} \\
        \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\
        \frac{\partial \theta_{iD}'}{\partial \theta_0} &amp;amp; \frac{\partial \theta_{iD}'}{\partial \theta_1} &amp;amp; \dots &amp;amp; \frac{\partial \theta_{iD}'}{\partial \theta_D}
    \end{bmatrix}
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;By definition, &lt;/p&gt;
&lt;p&gt;$$
\begin{equation} \label{eq8}
    \theta_{ij}' = \theta_j - \alpha \frac{\partial L_{T_i}(\theta)}{\partial \theta_j}
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;Calculating a few terms of the Jacobian,
$$
\begin{equation*}
    \frac{\partial \theta_{i0}'}{\partial \theta_0} = 1 - \alpha \frac{\partial^2 L_{T_i}(\theta)}{\partial^2 \theta_0} \\
    \frac{\partial \theta_{i0}'}{\partial \theta_1} = -\alpha \frac{\partial^2 L_{T_i}(\theta)}{\partial \theta_0 \partial \theta_1}
\end{equation*}
$$&lt;/p&gt;
&lt;p&gt;Generalizing,&lt;/p&gt;
&lt;p&gt;$$
\begin{equation} \label{eq9}
    \frac{\partial \theta_{ip}'}{\partial \theta_q} = 
    \begin{cases}
        1 - \alpha \frac{\partial^2 L_{T_i}(\theta)}{\partial^2 \theta_q}, &amp;amp; \text{if } p = q \\
        -\alpha \frac{\partial^2 L_{T_i}(\theta)}{\partial \theta_p \partial \theta_q}, &amp;amp; {p \neq q}
    \end{cases}
\end{equation}
$$
&lt;!-- Double Derivative start --&gt;
&lt;br /&gt;
Let us calculate the double derivative term $ \frac{\partial^2 L_{T_i}(f_{\theta})}{\partial^2 \theta} $,&lt;/p&gt;
&lt;p&gt;$$
\begin{equation} \label{eq10}
    \frac{\partial^2 L_{T_i}(f_{\theta})}{\partial^2 \theta} = 
    \begin{bmatrix}
        \frac{\partial^2 L_{T_i}(f_{\theta})}{\partial^2 \theta_0} &amp;amp; \frac{\partial^2 L_{T_i}(f_{\theta})}{\partial \theta_0 \partial \theta_1} &amp;amp; \dots &amp;amp; \frac{\partial^2 L_{T_i}(f_{\theta})}{\partial \theta_0 \partial \theta_D} \\
        \frac{\partial^2 L_{T_i}(f_{\theta})}{\partial \theta_1 \partial \theta_0} &amp;amp; \frac{\partial^2 L_{T_i}(f_{\theta})}{\partial^2 \theta_1} &amp;amp; \dots &amp;amp; \frac{\partial^2 L_{T_i}(f_{\theta})}{\partial \theta_1 \partial \theta_D} \\
        \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\
        \frac{\partial^2 L_{T_i}(f_{\theta})}{\partial \theta_D \partial \theta_0} &amp;amp; \frac{\partial^2 L_{T_i}(f_{\theta})}{\partial \theta_D \partial \theta_1} &amp;amp; \dots &amp;amp; \frac{\partial^2 L_{T_i}(f_{\theta})}{\partial^2 \theta_D}
    \end{bmatrix}
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;Thus, 
$$
\begin{equation} \label{eq11}
    \frac{\partial L_{T_i}(\theta)}{\partial \theta_q} = \sum_{j = 1}^K (f_\theta (x^{(j)}) - y^{(j)}) \cdot \frac{\partial f_{\theta}}{\partial \theta_q} (x^{(j)})
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;$$
\begin{equation} \label{eq12}
    \frac{\partial^2 L_{T_i}(\theta)}{\partial \theta_p \partial \theta_q} = \sum_{j = 1}^K [(f_\theta (x^{(j)}) - y^{(j)}) \cdot \frac{\partial^2 f_{\theta}}{\partial \theta_p \partial \theta_q} (x^{(j)}) + \frac{\partial f_{\theta}}{\partial \theta_p} (x^{(j)}) \cdot \frac{\partial f_{\theta}}{\partial \theta_q} (x^{(j)})]
\end{equation}
$$&lt;/p&gt;
&lt;!-- Double Derivative end --&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;Therefore, using equation \ref{eq5}, \ref{eq8} &amp;amp; \ref{eq12} we can now compute the gradient for the $i^{th}$ task w.r.t. the meta-parameters: $ \frac{\partial L_{T_i}(f_{\theta_i'})}{\partial \theta} $ (equation \ref{eq4})&lt;/p&gt;
&lt;p&gt;$$
\begin{equation} \label{eq13}
    \frac{\partial L_{T_i}(f_{\theta_i'})}{\partial \theta} = \sum_{k = 1}^K (f_{\theta_i'}(x^{(k)}) - y^{(k)}) \cdot \frac{\partial f_{\theta_i'}}{\partial \theta_i'} (x^{(k)}) \cdot \frac{\partial \theta_i'}{\partial \theta}
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;Calculating the gradient for all the $n$ tasks &amp;amp; summing them up will give us $ \nabla_\theta\sum_{T_{i = 1}}^n L_{T_i}(f_{\theta_i'}) $ (equation \ref{eq2})&lt;/p&gt;
&lt;p&gt;We can now perform our meta-update,  &lt;/p&gt;
&lt;p&gt;$$
\begin{equation*}
    \theta := \theta - \beta \nabla_\theta\sum_{T_{i = 1}}^n L_{T_i}(f_{\theta_i'})
\end{equation*}
$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;Chelsea Finn, Pieter Abbeel, and Sergey Levine. &lt;a href="https://arxiv.org/pdf/1703.03400.pdf"&gt;“Model-agnostic meta-learning for fast adaptation of deep networks.”&lt;/a&gt; ICML 2017.&lt;/p&gt;</content><category term="posts"></category></entry><entry><title>Deriving the MAML Objective - 1</title><link href="https://vdevmcitylp.github.io/deriving-the-maml-objective-1.html" rel="alternate"></link><published>2019-11-05T16:20:00+05:30</published><updated>2019-11-07T18:00:00+05:30</updated><author><name>Vaasudev Narayanan</name></author><id>tag:vdevmcitylp.github.io,2019-11-05:/deriving-the-maml-objective-1.html</id><summary type="html"></summary><content type="html">&lt;p&gt;In this blog post, we'll be deriving the meta-gradient for the &lt;a href="https://arxiv.org/pdf/1703.03400.pdf"&gt;Model Agnostic Meta Learning (MAML)&lt;/a&gt; objective. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Supervised MAML" src="https://vdevmcitylp.github.io/images/maml-supervised.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Fig: Supervised MAML&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Suppose we have $n$ tasks. Then the &lt;em&gt;meta-update&lt;/em&gt; given by step 10 in above algorithm is defined as,&lt;/p&gt;
&lt;p&gt;$$
\begin{equation} \label{eq1}
    \theta := \theta - \beta \nabla_\theta\sum_{T_{i = 1}}^n L_{T_i}(f_{\theta_i'})
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;Expanding the summation,&lt;/p&gt;
&lt;p&gt;$$
\begin{equation} 
    \begin{split}
        \nabla_\theta\sum_{T_{i = 1}}^n L_{T_i}(f_{\theta_i'}) &amp;amp; = \nabla_\theta (L_{T_1}(f_{\theta_1'}) + \dots + L_{T_i}(f_{\theta_i'}) + \dots + L_{T_n}(f_{\theta_n'})) \\
        &amp;amp;= \nabla_\theta L_{T_1}(f_{\theta_1'}) + \dots + \nabla_\theta L_{T_i}(f_{\theta_i'}) + \dots + \nabla_\theta L_{T_n}(f_{\theta_n'})
    \end{split}
    \label{eq2}
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;Noting the equivalence of the gradient operator and partial derivative notation,&lt;/p&gt;
&lt;p&gt;$$
\begin{equation*}
    \nabla_\theta L_{T_i}(f_{\theta_i'}) = \frac{\partial L_{T_i}(f_{\theta_i'})}{\partial \theta}
\end{equation*}
$$&lt;/p&gt;
&lt;p&gt;Let us calculate the gradient for the $i^{th}$ task,&lt;/p&gt;
&lt;p&gt;$$
\begin{equation} \label{eq3}
    \frac{\partial L_{T_i}(f_{\theta_i'})}{\partial \theta} = \frac{\partial L_{T_i}(f_{\theta_i'})}{\partial \theta_i'} \cdot
    \frac{\partial \theta_i'}{\partial \theta}
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;The first term of equation \ref{eq3}, $ \frac{\partial L_{T_i}(f_{\theta_i'})}{\partial \theta_i'} $ is the derivative of the task loss function w.r.t. to the task-adapted parameters, which is relatively straightforward to compute.&lt;/p&gt;
&lt;p&gt;$$ 
\begin{equation} \label{eq4}
    \frac{\partial L_{T_i}(f_{\theta_i'})}{\partial \theta_i'} = \frac{\partial L_{T_i}(f_{\theta_i'})}{\partial f_{\theta_i'}} \cdot \frac{\partial f_{\theta_i'}}{\partial \theta_i'} 
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;The second term of equation \ref{eq3}, $ \frac{\partial \theta_i'}{\partial \theta} $ is the derivative of the task-adapted parameters w.r.t. the meta-parameters.&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;To calculate $ \frac{\partial \theta_i'}{\partial \theta} $, we see that&lt;/p&gt;
&lt;p&gt;$$
\begin{equation} \label{eq5}
    \theta_i' = \theta - \alpha \frac{\partial L_{T_i}(f_{\theta})}{\partial \theta}
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;Therefore,&lt;/p&gt;
&lt;p&gt;$$
\begin{equation} \label{eq6}
    \frac{\partial \theta_i}{\partial \theta} = I - \alpha \frac{\partial^2 L_{T_i}(f_{\theta})}{\partial^2 \theta}
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;Expanding the double derivative term $ \frac{\partial^2 L_{T_i}(f_{\theta})}{\partial^2 \theta} $,
$$
\begin{equation}
    \begin{split}
        \frac{\partial^2 L_{T_i}(f_{\theta})}{\partial^2 \theta} &amp;amp;= \frac{\partial }{\partial \theta}\frac{\partial L_{T_i}(f_{\theta})}{\partial \theta} \\
        &amp;amp;= \frac{\partial }{\partial \theta}[\frac{\partial L_{T_i}(f_{\theta})}{\partial f_\theta} \cdot \frac{\partial f_\theta}{\partial \theta}] \\
        &amp;amp;= \frac{\partial L_{T_i}(f_{\theta})}{\partial f_\theta} \cdot \frac{\partial^2 f_\theta}{\partial^2 \theta} + \frac{\partial^2 L_{T_i}(f_{\theta})}{\partial^2 f_\theta} \cdot (\frac{\partial f_\theta}{\partial \theta})^2
    \end{split}
    \label{eq7}
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;Plugging $ \frac{\partial^2 L_{T_i}(f_{\theta})}{\partial^2 \theta} $ in equation \ref{eq6}, will give us $ \frac{\partial \theta_i}{\partial \theta} $&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;Thus, using equation \ref{eq4}, \ref{eq6} &amp;amp; \ref{eq7} we can now compute the gradient for the $i^{th}$ task w.r.t. the meta-parameters: $ \frac{\partial L_{T_i}(f_{\theta_i'})}{\partial \theta} $ (equation \ref{eq3})&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;Calculating the gradient for all the $n$ tasks &amp;amp; summing them up will give us $ \nabla_\theta\sum_{T_{i = 1}}^n L_{T_i}(f_{\theta_i'}) $ (equation \ref{eq2})&lt;/p&gt;
&lt;p&gt;We can now perform our meta-update,  &lt;/p&gt;
&lt;p&gt;$$
\begin{equation*}
    \theta := \theta - \beta \nabla_\theta\sum_{T_{i = 1}}^n L_{T_i}(f_{\theta_i'})
\end{equation*}
$$&lt;/p&gt;
&lt;p&gt;In the &lt;a href="https://vdevmcitylp.github.io/deriving-the-maml-objective-2.html"&gt;next&lt;/a&gt; post, we will see how the derivation works out for Mean Squared Error (MSE) loss.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;Chelsea Finn, Pieter Abbeel, and Sergey Levine. &lt;a href="https://arxiv.org/pdf/1703.03400.pdf"&gt;“Model-agnostic meta-learning for fast adaptation of deep networks.”&lt;/a&gt; ICML 2017.&lt;/p&gt;</content><category term="posts"></category></entry><entry><title>It's a process.</title><link href="https://vdevmcitylp.github.io/its-a-process.html" rel="alternate"></link><published>2019-10-21T11:00:00+05:30</published><updated>2019-04-21T11:00:00+05:30</updated><author><name>Vaasudev Narayanan</name></author><id>tag:vdevmcitylp.github.io,2019-10-21:/its-a-process.html</id><summary type="html">&lt;p&gt;My thoughts about research.&lt;/p&gt;</summary><content type="html">&lt;p&gt;On &lt;a href="https://medium.com/@vaasudev96/its-a-process-54c29c6c5ffb"&gt;Medium&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For as long as I can remember, I’ve wanted to be a scientist. It’s only in the past few years though that I’ve started to understand what it truly means to be a scientist and how much I enjoy being one!&lt;/p&gt;
&lt;p&gt;I’ve worked in a few academic &amp;amp; industrial labs doing research in machine learning &amp;amp; its applications. I’ve had the fortune of being advised by brilliant researchers and the majority of the things that I’ve learnt, I would attribute it to them.&lt;/p&gt;
&lt;p&gt;I thought I’d write up a blog post and share some things that I’ve learnt along the way.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: I’m relatively a young researcher and have been involved in machine learning research for about two years now.&lt;/p&gt;
&lt;p&gt;So with that out of the way, here’s a list of things I wish I had known when I was just starting out my career in research.&lt;br&gt;
&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Skepticism&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Yes, I’d like to start on a positive note by telling you to be a pessimist and not to trust anything blindly. It is important to question everything that you come across, now more so than ever where the field is moving so fast with a deluge of papers being published everyday. When you read a paper, ask whether they’ve followed the proper scientific method, ask whether the underlying assumptions that the paper uses are valid and whether the experimental results support what the authors originally set out to show.&lt;/p&gt;
&lt;p&gt;With regard to your own experiments, be highly skeptical of whatever results you get. Try to come up with alternative explanations for your results and systematically rule them out one by one. Conduct proper ablation studies to ascertain that you can establish a correlation between your hypothesis and your result.
I know it feels good when the results support your hypothesis, but by considering alternative explanations you can be more confident about your work.  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Simplicity&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Start with simple experiments. It is very tempting to conjure up a complicated model and hope that it will produce state-of-the-art results for your task on the first shot. Unfortunately, that happens rarely.&lt;/p&gt;
&lt;p&gt;Perform simple experiments first, establish proper baselines and then move forward accordingly. [Unless you are an absolute genius and know what you’re doing, go ahead with whatever feels right for you. This advice is for plebeians like me.]  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Literature Review&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There is a good chance that prior attempts have been made to tackle the problem that you’re trying to solve. You can save a lot of time and effort by studying approaches that have been taken in the past for your problem. By understanding where they worked and where they did not work, you can avoid making the same mistakes. Unless you have good reason to suspect prior research, avoid reinventing the wheel.  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Asking for Help&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;At times, you might lose track of the overall goal of your project and feel like you’re stuck in a rut. Consider asking someone else to have a look at your work. It is easier for an outsider to have a bird’s eye view of your project and provide fresh insights.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Make it easy for people to help you.&lt;/em&gt; Provide them with a short presentation or a write-up summarizing your work instead of dumping all your rough notes and code on them. They will appreciate the effort and will possibly go out of their way to help you.&lt;/p&gt;
&lt;p&gt;Conversely, make a genuine effort when people ask you for help. You can always say no if you feel they aren’t respecting your time and effort.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Research can get frustrating and at times you might feel the universe is against you. But don’t forget that &lt;a href="https://youtu.be/642kB411kRc"&gt;it’s a process&lt;/a&gt;!&lt;/p&gt;</content><category term="posts"></category></entry></feed>